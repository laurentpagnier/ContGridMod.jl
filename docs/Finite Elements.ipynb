{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Revise\n",
    "using ContGridMod\n",
    "using Ferrite\n",
    "using FerriteViz\n",
    "using GLMakie\n",
    "using SparseArrays\n",
    "using LinearAlgebra\n",
    "using Flux\n",
    "using Random\n",
    "using Plots\n",
    "Makie.inline!(true);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NTRAIN = 48;\n",
    "NTEST = 12;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid, scale_factor = get_grid(\"../data/borders/euro_border.json\", 0.1, \"panta.msh\");\n",
    "dm = load_discrete_model(\"../data/ml/test_1.h5\", scale_factor);\n",
    "model = get_params(grid, .05, dm, κ=0.02, bfactor=50000., σ=0.01, bmin=1);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load all discrete models\n",
    "trainingDiscMod = ContGridMod.DiscModel[];\n",
    "testDiscMod = ContGridMod.DiscModel[];\n",
    "for i=1:NTRAIN\n",
    "    push!(trainingDiscMod, load_discrete_model(\n",
    "        \"../data/ml/training_\" * string(i) * \".h5\", scale_factor));\n",
    "end\n",
    "for i=1:NTEST\n",
    "    push!(testDiscMod, load_discrete_model(\n",
    "        \"../data/ml/test_\" * string(i) * \".h5\", scale_factor));\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure that all slack busses are the same\n",
    "slack = trainingDiscMod[1].id_gen[trainingDiscMod[1].id_slack]\n",
    "for i=1:NTRAIN\n",
    "    if trainingDiscMod[i].id_gen[trainingDiscMod[i].id_slack] != slack\n",
    "        println(i)\n",
    "    end\n",
    "end\n",
    "for i=1:NTEST\n",
    "    if testDiscMod[i].id_gen[testDiscMod[i].id_slack] != slack\n",
    "        println(i)\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up training and test sets\n",
    "trainingTheta = zeros(size(trainingDiscMod[1].th, 1), NTRAIN);\n",
    "testTheta = zeros(size(testDiscMod[1].th, 1), NTEST);\n",
    "trainingP = zeros(getnnodes(grid), NTRAIN);\n",
    "testP = zeros(getnnodes(grid), NTEST);\n",
    "for i=1:NTRAIN\n",
    "    update_model!(model, :p, trainingDiscMod[i], .05, κ=0.02, bfactor=50000., σ=0.01, bmin=1)\n",
    "    stable_sol!(model)\n",
    "    trainingP[:, i] = model.f₀;\n",
    "    trainingTheta[:, i] = trainingDiscMod[i].th;\n",
    "end\n",
    "for i=1:NTEST\n",
    "    update_model!(model, :p, testDiscMod[i], .05, κ=0.02, bfactor=50000., σ=0.01, bmin=1)\n",
    "    stable_sol!(model)\n",
    "    testP[:, i] = model.f₀;\n",
    "    testTheta[:, i] = testDiscMod[i].th;\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create matrices to obtain the mass matrix using just matrix multiplication and updating the susceptances in the quadrature points.\n",
    "A = zeros(ndofs(model.dh₁), 2 * getnquadpoints(model.cellvalues) * size(model.grid.cells,1))\n",
    "B = zeros(2 * getnquadpoints(model.cellvalues) * size(model.grid.cells,1), 2 * getnquadpoints(model.cellvalues) * size(model.grid.cells,1))\n",
    "q_coords = zeros(2 * getnquadpoints(model.cellvalues) * size(model.grid.cells,1), 2)\n",
    "n_basefuncs = getnbasefunctions(model.cellvalues)\n",
    "for (i, cell) in enumerate(CellIterator(model.dh₁))\n",
    "    Ferrite.reinit!(model.cellvalues, cell)    \n",
    "    dofs = celldofs(cell)\n",
    "    for q_point in 1:getnquadpoints(model.cellvalues)\n",
    "        x = spatial_coordinate(model.cellvalues, q_point, getcoordinates(cell))\n",
    "        dΩ = getdetJdV(model.cellvalues, q_point)\n",
    "        ix = 2 * (i - 1) * getnquadpoints(model.cellvalues) + 2 * q_point - 1\n",
    "        q_coords[ix, :] = q_coords[ix+1, :] = x\n",
    "        for j in 1:n_basefuncs\n",
    "            ∇φⱼ = shape_gradient(model.cellvalues, q_point, j)\n",
    "            A[dofs[j], ix:ix+1] = ∇φⱼ * sqrt(dΩ)\n",
    "    end\n",
    "end\n",
    "end\n",
    "A[model.ch.prescribed_dofs, :] .= 0\n",
    "A = sparse(A)\n",
    "dim = zeros(ndofs(model.dh₁), ndofs(model.dh₁))\n",
    "dim[model.ch.prescribed_dofs, model.ch.prescribed_dofs] .= 1\n",
    "dim = sparse(dim);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for (i, cell) in enumerate(CellIterator(model.dh₁))\n",
    "    if i==2\n",
    "        break\n",
    "    end\n",
    "    println(spatial_coordinate(model.cellvalues, 1, getcoordinates(cell))...)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The values to compare to the ground truth are obtained by interpolating between nodal values.\n",
    "# This can be broken down to matrix multiplication of a projection matrix and the nodal values\n",
    "func_interpolations = Ferrite.get_func_interpolations(model.dh₁, :u)\n",
    "proj = zeros(size(dm.th, 1), ndofs(model.dh₁))\n",
    "q_proj = zeros(size(q_coords, 1), 2 * ndofs(model.dh₁))\n",
    "grid_coords = [node.x for node in grid.nodes] \n",
    "\n",
    "for i = 1:size(dm.th, 1)\n",
    "    ph = PointEvalHandler(model.grid, [Ferrite.Vec(dm.coord[i, :]...)], warn=:false)\n",
    "    if ph.cells[1] === nothing\n",
    "        min_ix = argmin([norm(coord .- Ferrite.Vec(dm.coord[i, :]...)) for coord in grid_coords]) \n",
    "        ph = PointEvalHandler(grid, [grid_coords[min_ix]])\n",
    "    end\n",
    "    pv = Ferrite.PointScalarValuesInternal(ph.local_coords[1], func_interpolations[1])\n",
    "    cell_dofs = Vector{Int}(undef, ndofs_per_cell(model.dh₁, ph.cells[1]))\n",
    "    Ferrite.celldofs!(cell_dofs, model.dh₁, ph.cells[1])\n",
    "    n_base_funcs = getnbasefunctions(pv)\n",
    "    for j = 1:n_base_funcs\n",
    "        proj[i, cell_dofs[j]] = shape_value(pv, 1, j)\n",
    "    end\n",
    "end\n",
    "for (i, point) in enumerate(eachrow(q_coords))\n",
    "    ph = PointEvalHandler(model.grid, [Ferrite.Vec(point...)])\n",
    "    pv = Ferrite.PointScalarValuesInternal(ph.local_coords[1], func_interpolations[1])\n",
    "    cell_dofs = Vector{Int}(undef, ndofs_per_cell(model.dh₁, ph.cells[1]))\n",
    "    Ferrite.celldofs!(cell_dofs, model.dh₁, ph.cells[1])\n",
    "    n_base_funcs = getnbasefunctions(pv)\n",
    "    for j = 1:n_base_funcs\n",
    "        if mod(i, 2) == 0\n",
    "            q_proj[i, 2 * cell_dofs[j]] = shape_value(pv, 1, j)\n",
    "        else\n",
    "            q_proj[i, 2 * cell_dofs[j] - 1] = shape_value(pv, 1, j)\n",
    "        end\n",
    "    end\n",
    "end\n",
    "q_proj = sparse(q_proj);\n",
    "proj = sparse(proj);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the machine learning\n",
    "N = getnnodes(model.grid)\n",
    "opt = ADAM(0.1)\n",
    "b = 100 * rand(2 * ndofs(model.dh₁)) .+ 0.1\n",
    "param = Flux.params(b);\n",
    "nEpochs = 5000;\n",
    "nBatches = 3;\n",
    "batchSize = Int64(NTRAIN / nBatches);\n",
    "shuffledIx = randperm(NTRAIN);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Actual learning\n",
    "err = zeros(nEpochs * nBatches)\n",
    "for e=1:nEpochs\n",
    "    for batch=1:nBatches\n",
    "        local _err\n",
    "        gs = Flux.gradient(param) do\n",
    "            btemp = max.(b, 0.1)\n",
    "            K = sparse(A * diagm(q_proj * btemp) * A' + dim)\n",
    "            θ = proj * (K \\ trainingP[:, shuffledIx[(batch - 1) * batchSize + 1:batch * batchSize]])\n",
    "            _err = mean(abs2, θ .- trainingTheta[:, shuffledIx[(batch - 1) * batchSize + 1:batch * batchSize]])\n",
    "            return _err\n",
    "        end\n",
    "        if(mod(e,50) == 0 && batch == 1)\n",
    "            println([e _err])\n",
    "        end\n",
    "        err[(e - 1) * nBatches + batch] = _err\n",
    "        Flux.update!(opt, param, gs)\n",
    "    end\n",
    "end\n",
    "b = max.(b, 0.1);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = A * spdiagm(q_proj * b) * A' + dim\n",
    "trainingThetaPred =  proj * (K \\ trainingP)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Plots.plot(err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "update_model!(model, :bx, b[1:2:end])\n",
    "update_model!(model, :by, b[2:2:end])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Project values from quadrautre points onto nodal values\n",
    "# Note: a positive value in the quadrature points does NOT guarantee \n",
    "l2_proj = L2Projector(Ferrite.get_func_interpolations(model.dh₁, :u)[1], model.grid);\n",
    "bx = b[1:2:end]\n",
    "by = b[2:2:end]\n",
    "bx = [Ferrite.Vec(bx[(i - 1) * 3 + 1], bx[(i - 1) * 3 + 2], bx[(i - 1) * 3 + 3]) for i in 1:size(bx, 1)÷3];\n",
    "by = [Ferrite.Vec(by[(i - 1) * 3 + 1], by[(i - 1) * 3 + 2], by[(i - 1) * 3 + 3]) for i in 1:size(by, 1)÷3]\n",
    "bx_nodal = project(l2_proj, bx, QuadratureRule{2,RefTetrahedron}(2), project_to_nodes=false)\n",
    "by_nodal = project(l2_proj, by, QuadratureRule{2,RefTetrahedron}(2), project_to_nodes=false)\n",
    "update_model!(model, :bx, bx_nodal);\n",
    "update_model!(model, :by, by_nodal);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodal_plot(model, :bx_nodal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodal_plot(model, :by_nodal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stable_sol!(model)\n",
    "nodal_plot(model, :θ₀_nodal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the predictions for all disc models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ContGridMod.disc_plot(dm.coord[:,[2,1]], trainingDiscMod[NTRAIN].th)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingThetaPred = zeros(size(trainingDiscMod[1].th, 1), NTRAIN);\n",
    "testThetaPred = zeros(size(testDiscMod[1].th, 1), NTEST);\n",
    "for i=1:NTRAIN\n",
    "    update_model!(model, :p, trainingDiscMod[i], .05, κ=0.02, bfactor=50000., σ=0.01, bmin=1)\n",
    "    stable_sol!(model)\n",
    "    trainingThetaPred[:, i] = proj * model.θ₀_nodal;\n",
    "end\n",
    "for i=1:NTEST\n",
    "    update_model!(model, :p, testDiscMod[i], .05, κ=0.02, bfactor=50000., σ=0.01, bmin=1)\n",
    "    stable_sol!(model)\n",
    "    testThetaPred[:, i] = proj * model.θ₀_nodal;\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using DelimitedFiles\n",
    "writedlm(\"bxlearned.csv\", b[1:2:end], ',')\n",
    "writedlm(\"bylearned.csv\", b[2:2:end], ',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingPlots = Plots.Plot[]\n",
    "\n",
    "for i=1:NTRAIN\n",
    "    min, max = extrema([trainingTheta[:,i] trainingThetaPred[:,i]])\n",
    "    delta = max - min\n",
    "    pad = 0.05 * delta\n",
    "    min -= pad\n",
    "    max += pad\n",
    "push!(trainingPlots, Plots.scatter(trainingTheta[:,i], trainingThetaPred[:,i], xlims=(min, max), ylims=(min, max), label=\"Training Set \" * string(i)))\n",
    "end\n",
    "\n",
    "Plots.plot(trainingPlots..., layout=(12,4), size=(1500, 3000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testPlots = Plots.Plot[]\n",
    "\n",
    "for i=1:NTEST\n",
    "    min, max = extrema([testTheta[:,i] testThetaPred[:,i]])\n",
    "    delta = max - min\n",
    "    pad = 0.05 * delta\n",
    "    min -= pad\n",
    "    max += pad\n",
    "push!(testPlots, Plots.scatter(testTheta[:,i], testThetaPred[:,i], xlims=(min, max), ylims=(min, max), label=\"Test Set \" * string(i)))\n",
    "end\n",
    "\n",
    "Plots.plot(testPlots..., layout=(4,3), size=(1125, 1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_local_disturbance!(model, [0.25, -0.1], -9., 0.05)\n",
    "println(\"Synchronized freq: \", ContGridMod.integrate(model.dh₁, model.cellvalues, model.fault) / ContGridMod.integrate(model.dh₁, model.cellvalues, model.d))\n",
    "sol = perform_dyn_sim(model, 50.);\n",
    "save_simulation(model, sol, \"fault\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.8.5",
   "language": "julia",
   "name": "julia-1.8"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
